2024-06-17 11:40:59,927 - ============================== args ==============================
2024-06-17 11:40:59,927 - dataset: weibo
2024-06-17 11:40:59,927 - model: DEETSA
2024-06-17 11:40:59,927 - batch: 32
2024-06-17 11:40:59,927 - seed: 0
2024-06-17 11:40:59,927 - ============================== End args ==============================
2024-06-17 11:40:59,927 - ============================== config ==============================
2024-06-17 11:40:59,927 - BertModel: <class 'transformers.models.bert.modeling_bert.BertModel'>
2024-06-17 11:40:59,927 - BertTokenizer: <class 'transformers.models.bert.tokenization_bert.BertTokenizer'>
2024-06-17 11:40:59,927 - att_dropout: 0
2024-06-17 11:40:59,927 - att_num_heads: 8
2024-06-17 11:40:59,927 - batch_size: 32
2024-06-17 11:40:59,927 - bert_dir: ./bert-base-multilingual-uncased/
2024-06-17 11:40:59,927 - bert_freeze: False
2024-06-17 11:40:59,927 - classifier_hidden_dim: 128
2024-06-17 11:40:59,927 - decayRate: 0.96
2024-06-17 11:40:59,927 - device: cuda
2024-06-17 11:40:59,927 - epoch: 8
2024-06-17 11:40:59,927 - f_dropout: 0
2024-06-17 11:40:59,927 - hidden_dim: 768
2024-06-17 11:40:59,927 - img_dim: 2048
2024-06-17 11:40:59,927 - lr: 5e-05
2024-06-17 11:40:59,927 - max_captions_num: 6
2024-06-17 11:40:59,927 - max_images_num: 6
2024-06-17 11:40:59,927 - model_saved_path: ./best_model/
2024-06-17 11:40:59,927 - num_classes: 3
2024-06-17 11:40:59,927 - patience: 2
2024-06-17 11:40:59,928 - resnet101_path: ./ResNet/resnet101-5d3b4d8f.pth
2024-06-17 11:40:59,928 - resnet50_path: ./ResNet/resnet50-11ad3fa6.pth
2024-06-17 11:40:59,928 - test_ratio: 0.1
2024-06-17 11:40:59,928 - text_dim: 768
2024-06-17 11:40:59,928 - text_max_length: 40
2024-06-17 11:40:59,928 - torch: <module 'torch' from '/usr/local/lib/python3.8/dist-packages/torch/__init__.py'>
2024-06-17 11:40:59,928 - train_ratio: 0.8
2024-06-17 11:40:59,928 - twitter_dataset_dir: ./data/Twitter/
2024-06-17 11:40:59,928 - val_ratio: 0.1
2024-06-17 11:40:59,928 - weibo_dataset_dir: ./data/Weibo/
2024-06-17 11:40:59,928 - ============================== End config ==============================
2024-06-17 11:41:02,827 - total number of parameters:246152259
2024-06-17 11:41:02,830 - -----------Epoch:0-----------
2024-06-17 11:58:05,011 - train_loss:0.38012 train_acc:0.813
2024-06-17 11:59:35,826 - val_acc:7.20632 val_acc:0.340 

2024-06-17 11:59:37,870 - save model,acc:0.340
2024-06-17 11:59:37,870 - -----------Epoch:1-----------
2024-06-17 12:15:56,181 - train_loss:0.13424 train_acc:0.947
2024-06-17 12:17:28,938 - val_acc:0.29859 val_acc:0.891 

2024-06-17 12:17:30,856 - save model,acc:0.891
2024-06-17 12:17:30,857 - -----------Epoch:2-----------
2024-06-17 12:33:47,427 - train_loss:0.09940 train_acc:0.975
2024-06-17 12:35:18,280 - val_acc:0.33246 val_acc:0.909 

2024-06-17 12:35:20,170 - save model,acc:0.909
2024-06-17 12:35:20,170 - -----------Epoch:3-----------
2024-06-17 12:51:36,166 - train_loss:0.06695 train_acc:0.977
2024-06-17 12:53:06,839 - val_acc:0.36794 val_acc:0.919 

2024-06-17 12:53:08,777 - save model,acc:0.919
2024-06-17 12:53:08,778 - -----------Epoch:4-----------
2024-06-17 13:09:20,506 - train_loss:0.02064 train_acc:0.994
2024-06-17 13:10:50,753 - val_acc:0.40363 val_acc:0.903 

2024-06-17 13:10:50,753 - -----------Epoch:5-----------
2024-06-17 13:26:59,209 - train_loss:0.02215 train_acc:0.993
2024-06-17 13:28:29,589 - val_acc:0.30635 val_acc:0.901 

2024-06-17 13:30:03,062 - --------------------- test results-------------------------------
2024-06-17 13:30:03,063 - acc:0.9239577  prec:[0.99148935 0.88819873 0.92266667]  rec:[0.9748954  0.84117645 0.9558011 ]  f1:[0.98312235 0.86404836 0.93894166]
2024-06-17 13:30:03,063 - confusion: 
[[233   3   3]
 [  1 143  26]
 [  1  15 346]]
2024-06-17 13:30:03,127 - the running time is: 6540.3 s
