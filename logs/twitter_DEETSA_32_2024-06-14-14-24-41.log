2024-06-14 14:24:41,304 - ============================== args ==============================
2024-06-14 14:24:41,304 - dataset: twitter
2024-06-14 14:24:41,304 - model: DEETSA
2024-06-14 14:24:41,304 - batch: 32
2024-06-14 14:24:41,304 - seed: 0
2024-06-14 14:24:41,304 - ============================== End args ==============================
2024-06-14 14:24:41,304 - ============================== config ==============================
2024-06-14 14:24:41,304 - BertModel: <class 'transformers.models.bert.modeling_bert.BertModel'>
2024-06-14 14:24:41,305 - BertTokenizer: <class 'transformers.models.bert.tokenization_bert.BertTokenizer'>
2024-06-14 14:24:41,305 - att_dropout: 0
2024-06-14 14:24:41,305 - batch_size: 32
2024-06-14 14:24:41,305 - bert_dir: ./bert-base-multilingual-uncased/
2024-06-14 14:24:41,305 - bert_freeze: False
2024-06-14 14:24:41,305 - decayRate: 0.96
2024-06-14 14:24:41,305 - device: cuda
2024-06-14 14:24:41,305 - epoch: 8
2024-06-14 14:24:41,305 - f_dropout: 0
2024-06-14 14:24:41,305 - lr: 5e-05
2024-06-14 14:24:41,305 - max_captions_num: 5
2024-06-14 14:24:41,305 - max_images_num: 5
2024-06-14 14:24:41,305 - model_saved_path: ./best_model/
2024-06-14 14:24:41,305 - num_classes: 3
2024-06-14 14:24:41,305 - patience: 2
2024-06-14 14:24:41,305 - resnet101_path: ./ResNet/resnet101-5d3b4d8f.pth
2024-06-14 14:24:41,305 - resnet50_path: ./ResNet/resnet50-11ad3fa6.pth
2024-06-14 14:24:41,305 - test_ratio: 0.1
2024-06-14 14:24:41,305 - text_max_length: 40
2024-06-14 14:24:41,305 - torch: <module 'torch' from '/usr/local/lib/python3.8/dist-packages/torch/__init__.py'>
2024-06-14 14:24:41,305 - train_ratio: 0.8
2024-06-14 14:24:41,305 - twitter_dataset_dir: ./data/Twitter/
2024-06-14 14:24:41,305 - val_ratio: 0.1
2024-06-14 14:24:41,305 - weibo_dataset_dir: ./data/Weibo/
2024-06-14 14:24:41,305 - ============================== End config ==============================
2024-06-14 14:24:43,929 - total number of parameters:246152259
2024-06-14 14:24:43,932 - -----------Epoch:0-----------
2024-06-14 14:40:14,981 - train_loss:0.44772 train_acc:0.764
2024-06-14 14:41:41,982 - val_acc:0.23150 val_acc:0.902 

2024-06-14 14:41:43,892 - save model,acc:0.902
2024-06-14 14:41:43,893 - -----------Epoch:1-----------
2024-06-14 14:57:02,725 - train_loss:0.14705 train_acc:0.935
2024-06-14 14:58:28,623 - val_acc:0.28068 val_acc:0.896 

2024-06-14 14:58:28,624 - -----------Epoch:2-----------
2024-06-14 15:13:40,573 - train_loss:0.05584 train_acc:0.978
2024-06-14 15:15:06,891 - val_acc:0.26206 val_acc:0.912 

2024-06-14 15:15:08,781 - save model,acc:0.912
2024-06-14 15:15:08,781 - -----------Epoch:3-----------
2024-06-14 15:30:22,462 - train_loss:0.02331 train_acc:0.990
2024-06-14 15:31:49,024 - val_acc:0.27098 val_acc:0.917 

2024-06-14 15:31:50,890 - save model,acc:0.917
2024-06-14 15:31:50,891 - -----------Epoch:4-----------
2024-06-14 15:47:02,747 - train_loss:0.02650 train_acc:0.990
2024-06-14 15:48:29,344 - val_acc:0.35011 val_acc:0.904 

2024-06-14 15:48:29,344 - -----------Epoch:5-----------
2024-06-14 16:03:42,312 - train_loss:0.01208 train_acc:0.996
2024-06-14 16:05:08,447 - val_acc:0.33996 val_acc:0.900 

2024-06-14 16:06:43,441 - --------------------- test results-------------------------------
2024-06-14 16:06:43,442 - acc:0.9268106  prec:[0.96347034 0.85       0.95955884]  rec:[0.96347034 0.86440676 0.95255476]  f1:[0.96347034 0.85714287 0.95604396]
2024-06-14 16:06:43,442 - confusion: 
[[211   6   2]
 [  7 102   9]
 [  1  12 261]]
2024-06-14 16:06:43,508 - the running time is: 6119.6 s
